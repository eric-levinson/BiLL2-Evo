import { NextResponse } from 'next/server'
import { createServerSupabaseClient } from '@/lib/supabase/server'
import { createMCPClient } from '@ai-sdk/mcp'
import {
  ToolLoopAgent,
  stepCountIs,
  createAgentUIStreamResponse,
  consumeStream,
  type UIMessage
} from 'ai'
import { anthropic } from '@ai-sdk/anthropic'
import { detectProvider } from '@/lib/ai/providerDetection'
import { registerToolSearch } from '@/lib/ai/anthropicToolSearch'
import { buildBM25Index } from '@/lib/ai/bm25Index'
import { createPrepareStepCallback } from '@/lib/ai/toolFiltering'

/**
 * Estimates token count for a tool definition
 * Rough heuristic: ~1.3 tokens per character (includes name, description, parameters)
 * @param toolName - Name of the tool
 * @param toolDef - Tool definition object with description and parameters
 * @returns Estimated token count
 */
function estimateToolTokens(toolName: string, toolDef: unknown): number {
  // Serialize the tool definition to JSON to estimate size
  const toolJson = JSON.stringify({
    name: toolName,
    ...toolDef
  })
  // Rough estimate: ~1.3 tokens per character (includes JSON structure overhead)
  return Math.ceil(toolJson.length / 0.77)
}

/**
 * Calculates total estimated tokens for a set of tools
 * @param tools - Record of tools or array of tool names with definitions
 * @returns Total estimated token count
 */
function calculateTotalTokens(tools: Record<string, unknown> | unknown[]): number {
  if (Array.isArray(tools)) {
    return tools.reduce((total, tool) => {
      // For BM25 search results, estimate based on the tool object
      return total + estimateToolTokens('tool', tool)
    }, 0)
  }

  // For tools Record from MCP
  return Object.entries(tools).reduce((total, [name, def]) => {
    return total + estimateToolTokens(name, def)
  }, 0)
}

// Helper to extract text content from UIMessage v3 parts
function getMessageText(message: UIMessage | undefined): string {
  if (!message) return 'New Chat'
  // UIMessage v3 uses parts array, not content string
  const textPart = message.parts?.find(
    (p): p is { type: 'text'; text: string } => p.type === 'text'
  )
  return textPart?.text || 'New Chat'
}

export async function POST(req: Request) {
  // Verify authentication
  const supabase = await createServerSupabaseClient()
  const { data } = await supabase.auth.getUser()
  const user = data?.user ?? null

  if (!user) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
  }

  let mcpClient

  try {
    // Parse request body
    const body = await req.json()
    // `id` is auto-generated by useChat SDK - we use a separate `sessionId` for DB persistence
    const { messages, sessionId } = body

    if (!messages || !Array.isArray(messages)) {
      return NextResponse.json(
        { error: 'Messages array is required' },
        { status: 400 }
      )
    }

    // Create MCP client with streamable HTTP transport
    const mcpServerUrl =
      process.env.MCP_SERVER_URL || 'http://localhost:8000/mcp/'
    mcpClient = await createMCPClient({
      transport: {
        type: 'http',
        url: mcpServerUrl
      }
    })

    // Get all available tools from MCP server
    const tools = await mcpClient.tools()

    // Detect provider from model ID
    const modelId = process.env.AI_MODEL_ID || 'claude-sonnet-4-20250514'
    const provider = detectProvider(modelId)

    // Get max results for tool filtering from env var
    const maxResults = parseInt(process.env.TOOL_SEARCH_MAX_RESULTS || '7', 10)

    // Calculate baseline token count (all tools)
    const totalToolCount = Object.keys(tools).length
    const baselineTokens = calculateTotalTokens(tools)

    console.log(`[Tool Filtering] Provider: ${provider}, Model: ${modelId}`)
    console.log(`[Tool Filtering] Total tools available: ${totalToolCount}`)
    console.log(`[Tool Filtering] Estimated baseline tokens (all tools): ${baselineTokens.toLocaleString()}`)

    // Convert tools Record to array for BM25 indexing
    const toolsArray = Object.values(tools)

    // Build BM25 index for client-side tool filtering (used by non-Anthropic providers)
    const bm25Index = buildBM25Index(toolsArray)

    // Apply Tool Search optimization for Anthropic models
    // For Claude, this marks all MCP tools with deferLoading: true
    // and adds the Tool Search meta-tool for on-demand discovery
    const optimizedTools = provider === 'anthropic'
      ? registerToolSearch(tools)
      : tools

    // Log path-specific optimization strategy
    if (provider === 'anthropic') {
      // Anthropic Tool Search: Server-side on-demand tool loading
      // Estimated tokens: ~500 for Tool Search meta-tool + selected tools loaded on-demand
      const estimatedFilteredTokens = 500 + (maxResults * (baselineTokens / totalToolCount))
      const tokenSavings = baselineTokens - estimatedFilteredTokens
      const savingsPercentage = ((tokenSavings / baselineTokens) * 100).toFixed(1)

      console.log(`[Tool Filtering] Strategy: Anthropic Tool Search (server-side)`)
      console.log(`[Tool Filtering] Estimated filtered tokens: ${estimatedFilteredTokens.toLocaleString()} (Tool Search meta-tool + ~${maxResults} tools on-demand)`)
      console.log(`[Tool Filtering] Estimated token savings: ${tokenSavings.toLocaleString()} tokens (${savingsPercentage}% reduction)`)
    } else {
      // Client-side BM25: Tools filtered before each LLM step via prepareStep
      const estimatedFilteredTokens = maxResults * (baselineTokens / totalToolCount)
      const tokenSavings = baselineTokens - estimatedFilteredTokens
      const savingsPercentage = ((tokenSavings / baselineTokens) * 100).toFixed(1)

      console.log(`[Tool Filtering] Strategy: Client-side BM25 filtering via prepareStep`)
      console.log(`[Tool Filtering] Estimated filtered tokens: ${estimatedFilteredTokens.toLocaleString()} (~${maxResults} tools per request)`)
      console.log(`[Tool Filtering] Estimated token savings: ${tokenSavings.toLocaleString()} tokens (${savingsPercentage}% reduction)`)
    }

    // Create prepareStep callback for BM25 filtering (non-Anthropic providers)
    // For Anthropic providers, Tool Search handles this server-side, so no prepareStep needed
    // Wrap the callback to add logging
    const basePrepareStep = provider !== 'anthropic'
      ? createPrepareStepCallback(bm25Index, toolsArray, maxResults)
      : undefined

    const prepareStep = basePrepareStep
      ? (context: Parameters<typeof basePrepareStep>[0]) => {
          const result = basePrepareStep(context)

          // Log selected tools for this step
          if (result.activeTools && result.activeTools.length > 0) {
            console.log(`[Tool Selection] BM25 selected ${result.activeTools.length} tools: ${result.activeTools.join(', ')}`)
          } else {
            console.log(`[Tool Selection] BM25 fallback: using all ${totalToolCount} tools`)
          }

          return result
        }
      : undefined

    // Create ToolLoopAgent with Claude
    const agent = new ToolLoopAgent({
      model: anthropic(modelId),
      tools: optimizedTools,
      stopWhen: stepCountIs(10),
      prepareStep,
      instructions: `You are BiLL, an advanced fantasy football analyst powered by AI.

Your capabilities:
- Access to comprehensive NFL player stats (season & weekly advanced metrics)
- Real-time Sleeper league data (rosters, matchups, transactions, trending players)
- Dynasty and redraft rankings
- Game-level offensive and defensive statistics
- Player information and metrics metadata

Guidelines for tool usage:
1. Always use the appropriate tools to fetch data rather than relying on your training data
2. For player lookups, start with get_player_info_tool to get accurate player IDs and current team info
3. When analyzing stats, use the advanced stats tools (receiving/passing/rushing/defense) for deeper insights
4. For league-specific questions, use Sleeper API tools to get current roster and matchup data
5. When discussing rankings, fetch the latest dynasty or redraft rankings via get_fantasy_ranks
6. Provide data-driven insights and back up your recommendations with specific metrics
7. If you need clarification on available metrics, use get_metrics_metadata

Remember:
- Be conversational but analytical
- Cite specific stats when making recommendations
- Consider both current performance and historical trends
- For dynasty leagues, factor in player age and long-term value
- Always verify player names and team affiliations before making claims`
    })

    // Use createAgentUIStreamResponse which properly handles the agent stream
    return createAgentUIStreamResponse({
      agent,
      uiMessages: messages,
      // CRITICAL: Consume stream to ensure completion even on client disconnect
      // This prevents data loss when client closes browser or network disconnects
      consumeSseStream: consumeStream,
      // SERVER-SIDE persistence - fires even when client disconnects
      onFinish: async ({ messages: completedMessages }) => {
        try {
          if (!sessionId) {
            // Create new session with title from first user message
            const firstUserMessage = completedMessages.find(
              (m: UIMessage) => m.role === 'user'
            )
            const content = getMessageText(firstUserMessage)

            // Truncate title to 50 chars max (47 chars + '...')
            const title =
              content.length > 50 ? content.substring(0, 47) + '...' : content

            // Insert new session into database
            const { data: newSession, error: insertError } = await supabase
              .from('chat_sessions')
              .insert({
                user_id: user.id,
                title,
                messages: completedMessages
              })
              .select('id')
              .single()

            if (insertError) {
              console.error('Server-side session creation failed:', insertError)
            } else {
              console.log(
                'Server-side persistence: Created new session:',
                newSession?.id,
                'with title:',
                title
              )
            }
          } else {
            // Update existing session with new messages
            const { error: updateError } = await supabase
              .from('chat_sessions')
              .update({
                messages: completedMessages
              })
              .eq('id', sessionId)

            if (updateError) {
              console.error('Server-side session update failed:', updateError)
            } else {
              console.log('Server-side persistence: Updated session', sessionId)
            }
          }
        } catch (err) {
          console.error('Server-side persistence error:', err)
          // Don't throw - we don't want to break the streaming response
        }
      }
    })
  } catch (err) {
    console.error('Chat API error:', err)
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    )
  } finally {
    // Close MCP client to prevent resource leaks
    if (mcpClient) {
      await mcpClient.close()
    }
  }
}
